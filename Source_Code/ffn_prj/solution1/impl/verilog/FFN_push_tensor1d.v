// ==============================================================
// Generated by Vitis HLS v2025.1
// Copyright 1986-2022 Xilinx, Inc. All Rights Reserved.
// Copyright 2022-2025 Advanced Micro Devices, Inc. All Rights Reserved.
// ==============================================================

`timescale 1 ns / 1 ps 

module FFN_push_tensor1d (
        ap_clk,
        ap_rst,
        ap_start,
        ap_done,
        ap_idle,
        ap_ready,
        m_axi_gmem_0_AWVALID,
        m_axi_gmem_0_AWREADY,
        m_axi_gmem_0_AWADDR,
        m_axi_gmem_0_AWID,
        m_axi_gmem_0_AWLEN,
        m_axi_gmem_0_AWSIZE,
        m_axi_gmem_0_AWBURST,
        m_axi_gmem_0_AWLOCK,
        m_axi_gmem_0_AWCACHE,
        m_axi_gmem_0_AWPROT,
        m_axi_gmem_0_AWQOS,
        m_axi_gmem_0_AWREGION,
        m_axi_gmem_0_AWUSER,
        m_axi_gmem_0_WVALID,
        m_axi_gmem_0_WREADY,
        m_axi_gmem_0_WDATA,
        m_axi_gmem_0_WSTRB,
        m_axi_gmem_0_WLAST,
        m_axi_gmem_0_WID,
        m_axi_gmem_0_WUSER,
        m_axi_gmem_0_ARVALID,
        m_axi_gmem_0_ARREADY,
        m_axi_gmem_0_ARADDR,
        m_axi_gmem_0_ARID,
        m_axi_gmem_0_ARLEN,
        m_axi_gmem_0_ARSIZE,
        m_axi_gmem_0_ARBURST,
        m_axi_gmem_0_ARLOCK,
        m_axi_gmem_0_ARCACHE,
        m_axi_gmem_0_ARPROT,
        m_axi_gmem_0_ARQOS,
        m_axi_gmem_0_ARREGION,
        m_axi_gmem_0_ARUSER,
        m_axi_gmem_0_RVALID,
        m_axi_gmem_0_RREADY,
        m_axi_gmem_0_RDATA,
        m_axi_gmem_0_RLAST,
        m_axi_gmem_0_RID,
        m_axi_gmem_0_RFIFONUM,
        m_axi_gmem_0_RUSER,
        m_axi_gmem_0_RRESP,
        m_axi_gmem_0_BVALID,
        m_axi_gmem_0_BREADY,
        m_axi_gmem_0_BRESP,
        m_axi_gmem_0_BID,
        m_axi_gmem_0_BUSER,
        tsor,
        x_strm_din,
        x_strm_full_n,
        x_strm_write
);

parameter    ap_ST_fsm_state1 = 13'd1;
parameter    ap_ST_fsm_state2 = 13'd2;
parameter    ap_ST_fsm_state3 = 13'd4;
parameter    ap_ST_fsm_state4 = 13'd8;
parameter    ap_ST_fsm_state5 = 13'd16;
parameter    ap_ST_fsm_state6 = 13'd32;
parameter    ap_ST_fsm_state7 = 13'd64;
parameter    ap_ST_fsm_state8 = 13'd128;
parameter    ap_ST_fsm_state9 = 13'd256;
parameter    ap_ST_fsm_state10 = 13'd512;
parameter    ap_ST_fsm_state11 = 13'd1024;
parameter    ap_ST_fsm_state12 = 13'd2048;
parameter    ap_ST_fsm_state13 = 13'd4096;

input   ap_clk;
input   ap_rst;
input   ap_start;
output   ap_done;
output   ap_idle;
output   ap_ready;
output   m_axi_gmem_0_AWVALID;
input   m_axi_gmem_0_AWREADY;
output  [63:0] m_axi_gmem_0_AWADDR;
output  [0:0] m_axi_gmem_0_AWID;
output  [31:0] m_axi_gmem_0_AWLEN;
output  [2:0] m_axi_gmem_0_AWSIZE;
output  [1:0] m_axi_gmem_0_AWBURST;
output  [1:0] m_axi_gmem_0_AWLOCK;
output  [3:0] m_axi_gmem_0_AWCACHE;
output  [2:0] m_axi_gmem_0_AWPROT;
output  [3:0] m_axi_gmem_0_AWQOS;
output  [3:0] m_axi_gmem_0_AWREGION;
output  [0:0] m_axi_gmem_0_AWUSER;
output   m_axi_gmem_0_WVALID;
input   m_axi_gmem_0_WREADY;
output  [31:0] m_axi_gmem_0_WDATA;
output  [3:0] m_axi_gmem_0_WSTRB;
output   m_axi_gmem_0_WLAST;
output  [0:0] m_axi_gmem_0_WID;
output  [0:0] m_axi_gmem_0_WUSER;
output   m_axi_gmem_0_ARVALID;
input   m_axi_gmem_0_ARREADY;
output  [63:0] m_axi_gmem_0_ARADDR;
output  [0:0] m_axi_gmem_0_ARID;
output  [31:0] m_axi_gmem_0_ARLEN;
output  [2:0] m_axi_gmem_0_ARSIZE;
output  [1:0] m_axi_gmem_0_ARBURST;
output  [1:0] m_axi_gmem_0_ARLOCK;
output  [3:0] m_axi_gmem_0_ARCACHE;
output  [2:0] m_axi_gmem_0_ARPROT;
output  [3:0] m_axi_gmem_0_ARQOS;
output  [3:0] m_axi_gmem_0_ARREGION;
output  [0:0] m_axi_gmem_0_ARUSER;
input   m_axi_gmem_0_RVALID;
output   m_axi_gmem_0_RREADY;
input  [31:0] m_axi_gmem_0_RDATA;
input   m_axi_gmem_0_RLAST;
input  [0:0] m_axi_gmem_0_RID;
input  [8:0] m_axi_gmem_0_RFIFONUM;
input  [0:0] m_axi_gmem_0_RUSER;
input  [1:0] m_axi_gmem_0_RRESP;
input   m_axi_gmem_0_BVALID;
output   m_axi_gmem_0_BREADY;
input  [1:0] m_axi_gmem_0_BRESP;
input  [0:0] m_axi_gmem_0_BID;
input  [0:0] m_axi_gmem_0_BUSER;
input  [63:0] tsor;
output  [31:0] x_strm_din;
input   x_strm_full_n;
output   x_strm_write;

reg ap_done;
reg ap_idle;
reg ap_ready;
reg m_axi_gmem_0_ARVALID;
reg[63:0] m_axi_gmem_0_ARADDR;
reg[0:0] m_axi_gmem_0_ARID;
reg[31:0] m_axi_gmem_0_ARLEN;
reg[2:0] m_axi_gmem_0_ARSIZE;
reg[1:0] m_axi_gmem_0_ARBURST;
reg[1:0] m_axi_gmem_0_ARLOCK;
reg[3:0] m_axi_gmem_0_ARCACHE;
reg[2:0] m_axi_gmem_0_ARPROT;
reg[3:0] m_axi_gmem_0_ARQOS;
reg[3:0] m_axi_gmem_0_ARREGION;
reg[0:0] m_axi_gmem_0_ARUSER;
reg m_axi_gmem_0_RREADY;

(* fsm_encoding = "none" *) reg   [12:0] ap_CS_fsm;
wire    ap_CS_fsm_state1;
reg    gmem_blk_n_AR;
wire  signed [61:0] trunc_ln_fu_60_p4;
reg   [61:0] trunc_ln_reg_89;
wire    grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_ap_start;
wire    grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_ap_done;
wire    grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_ap_idle;
wire    grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_ap_ready;
wire    grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_AWVALID;
wire   [63:0] grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_AWADDR;
wire   [0:0] grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_AWID;
wire   [31:0] grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_AWLEN;
wire   [2:0] grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_AWSIZE;
wire   [1:0] grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_AWBURST;
wire   [1:0] grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_AWLOCK;
wire   [3:0] grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_AWCACHE;
wire   [2:0] grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_AWPROT;
wire   [3:0] grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_AWQOS;
wire   [3:0] grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_AWREGION;
wire   [0:0] grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_AWUSER;
wire    grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_WVALID;
wire   [31:0] grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_WDATA;
wire   [3:0] grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_WSTRB;
wire    grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_WLAST;
wire   [0:0] grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_WID;
wire   [0:0] grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_WUSER;
wire    grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARVALID;
wire   [63:0] grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARADDR;
wire   [0:0] grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARID;
wire   [31:0] grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARLEN;
wire   [2:0] grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARSIZE;
wire   [1:0] grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARBURST;
wire   [1:0] grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARLOCK;
wire   [3:0] grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARCACHE;
wire   [2:0] grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARPROT;
wire   [3:0] grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARQOS;
wire   [3:0] grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARREGION;
wire   [0:0] grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARUSER;
wire    grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_RREADY;
wire    grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_BREADY;
wire   [31:0] grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_x_strm_din;
wire    grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_x_strm_write;
reg    grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_ap_start_reg;
wire    ap_CS_fsm_state12;
wire    ap_CS_fsm_state13;
wire  signed [63:0] sext_ln12_fu_70_p1;
reg   [12:0] ap_NS_fsm;
reg    ap_ST_fsm_state1_blk;
wire    ap_ST_fsm_state2_blk;
wire    ap_ST_fsm_state3_blk;
wire    ap_ST_fsm_state4_blk;
wire    ap_ST_fsm_state5_blk;
wire    ap_ST_fsm_state6_blk;
wire    ap_ST_fsm_state7_blk;
wire    ap_ST_fsm_state8_blk;
wire    ap_ST_fsm_state9_blk;
wire    ap_ST_fsm_state10_blk;
wire    ap_ST_fsm_state11_blk;
wire    ap_ST_fsm_state12_blk;
reg    ap_ST_fsm_state13_blk;
wire    ap_ce_reg;

// power-on initialization
initial begin
#0 ap_CS_fsm = 13'd1;
#0 grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_ap_start_reg = 1'b0;
end

FFN_push_tensor1d_Pipeline_VITIS_LOOP_12_1 grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51(
    .ap_clk(ap_clk),
    .ap_rst(ap_rst),
    .ap_start(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_ap_start),
    .ap_done(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_ap_done),
    .ap_idle(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_ap_idle),
    .ap_ready(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_ap_ready),
    .m_axi_gmem_0_AWVALID(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_AWVALID),
    .m_axi_gmem_0_AWREADY(1'b0),
    .m_axi_gmem_0_AWADDR(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_AWADDR),
    .m_axi_gmem_0_AWID(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_AWID),
    .m_axi_gmem_0_AWLEN(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_AWLEN),
    .m_axi_gmem_0_AWSIZE(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_AWSIZE),
    .m_axi_gmem_0_AWBURST(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_AWBURST),
    .m_axi_gmem_0_AWLOCK(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_AWLOCK),
    .m_axi_gmem_0_AWCACHE(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_AWCACHE),
    .m_axi_gmem_0_AWPROT(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_AWPROT),
    .m_axi_gmem_0_AWQOS(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_AWQOS),
    .m_axi_gmem_0_AWREGION(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_AWREGION),
    .m_axi_gmem_0_AWUSER(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_AWUSER),
    .m_axi_gmem_0_WVALID(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_WVALID),
    .m_axi_gmem_0_WREADY(1'b0),
    .m_axi_gmem_0_WDATA(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_WDATA),
    .m_axi_gmem_0_WSTRB(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_WSTRB),
    .m_axi_gmem_0_WLAST(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_WLAST),
    .m_axi_gmem_0_WID(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_WID),
    .m_axi_gmem_0_WUSER(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_WUSER),
    .m_axi_gmem_0_ARVALID(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARVALID),
    .m_axi_gmem_0_ARREADY(m_axi_gmem_0_ARREADY),
    .m_axi_gmem_0_ARADDR(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARADDR),
    .m_axi_gmem_0_ARID(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARID),
    .m_axi_gmem_0_ARLEN(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARLEN),
    .m_axi_gmem_0_ARSIZE(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARSIZE),
    .m_axi_gmem_0_ARBURST(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARBURST),
    .m_axi_gmem_0_ARLOCK(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARLOCK),
    .m_axi_gmem_0_ARCACHE(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARCACHE),
    .m_axi_gmem_0_ARPROT(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARPROT),
    .m_axi_gmem_0_ARQOS(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARQOS),
    .m_axi_gmem_0_ARREGION(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARREGION),
    .m_axi_gmem_0_ARUSER(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARUSER),
    .m_axi_gmem_0_RVALID(m_axi_gmem_0_RVALID),
    .m_axi_gmem_0_RREADY(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_RREADY),
    .m_axi_gmem_0_RDATA(m_axi_gmem_0_RDATA),
    .m_axi_gmem_0_RLAST(m_axi_gmem_0_RLAST),
    .m_axi_gmem_0_RID(m_axi_gmem_0_RID),
    .m_axi_gmem_0_RFIFONUM(m_axi_gmem_0_RFIFONUM),
    .m_axi_gmem_0_RUSER(m_axi_gmem_0_RUSER),
    .m_axi_gmem_0_RRESP(m_axi_gmem_0_RRESP),
    .m_axi_gmem_0_BVALID(1'b0),
    .m_axi_gmem_0_BREADY(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_BREADY),
    .m_axi_gmem_0_BRESP(2'd0),
    .m_axi_gmem_0_BID(1'd0),
    .m_axi_gmem_0_BUSER(1'd0),
    .x_strm_din(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_x_strm_din),
    .x_strm_full_n(x_strm_full_n),
    .x_strm_write(grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_x_strm_write),
    .sext_ln12(trunc_ln_reg_89)
);

always @ (posedge ap_clk) begin
    if (ap_rst == 1'b1) begin
        ap_CS_fsm <= ap_ST_fsm_state1;
    end else begin
        ap_CS_fsm <= ap_NS_fsm;
    end
end

always @ (posedge ap_clk) begin
    if (ap_rst == 1'b1) begin
        grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_ap_start_reg <= 1'b0;
    end else begin
        if ((1'b1 == ap_CS_fsm_state12)) begin
            grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_ap_start_reg <= 1'b1;
        end else if ((grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_ap_ready == 1'b1)) begin
            grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_ap_start_reg <= 1'b0;
        end
    end
end

always @ (posedge ap_clk) begin
    if ((1'b1 == ap_CS_fsm_state1)) begin
        trunc_ln_reg_89 <= {{tsor[63:2]}};
    end
end

assign ap_ST_fsm_state10_blk = 1'b0;

assign ap_ST_fsm_state11_blk = 1'b0;

assign ap_ST_fsm_state12_blk = 1'b0;

always @ (*) begin
    if ((grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_ap_done == 1'b0)) begin
        ap_ST_fsm_state13_blk = 1'b1;
    end else begin
        ap_ST_fsm_state13_blk = 1'b0;
    end
end

always @ (*) begin
    if (((m_axi_gmem_0_ARREADY == 1'b0) | (ap_start == 1'b0))) begin
        ap_ST_fsm_state1_blk = 1'b1;
    end else begin
        ap_ST_fsm_state1_blk = 1'b0;
    end
end

assign ap_ST_fsm_state2_blk = 1'b0;

assign ap_ST_fsm_state3_blk = 1'b0;

assign ap_ST_fsm_state4_blk = 1'b0;

assign ap_ST_fsm_state5_blk = 1'b0;

assign ap_ST_fsm_state6_blk = 1'b0;

assign ap_ST_fsm_state7_blk = 1'b0;

assign ap_ST_fsm_state8_blk = 1'b0;

assign ap_ST_fsm_state9_blk = 1'b0;

always @ (*) begin
    if ((((1'b1 == ap_CS_fsm_state1) & (ap_start == 1'b0)) | ((1'b1 == ap_CS_fsm_state13) & (grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_ap_done == 1'b1)))) begin
        ap_done = 1'b1;
    end else begin
        ap_done = 1'b0;
    end
end

always @ (*) begin
    if (((1'b1 == ap_CS_fsm_state1) & (ap_start == 1'b0))) begin
        ap_idle = 1'b1;
    end else begin
        ap_idle = 1'b0;
    end
end

always @ (*) begin
    if (((1'b1 == ap_CS_fsm_state13) & (grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_ap_done == 1'b1))) begin
        ap_ready = 1'b1;
    end else begin
        ap_ready = 1'b0;
    end
end

always @ (*) begin
    if (((1'b1 == ap_CS_fsm_state1) & (ap_start == 1'b1))) begin
        gmem_blk_n_AR = m_axi_gmem_0_ARREADY;
    end else begin
        gmem_blk_n_AR = 1'b1;
    end
end

always @ (*) begin
    if ((~((m_axi_gmem_0_ARREADY == 1'b0) | (ap_start == 1'b0)) & (1'b1 == ap_CS_fsm_state1))) begin
        m_axi_gmem_0_ARADDR = sext_ln12_fu_70_p1;
    end else if (((1'b1 == ap_CS_fsm_state13) | (1'b1 == ap_CS_fsm_state12))) begin
        m_axi_gmem_0_ARADDR = grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARADDR;
    end else begin
        m_axi_gmem_0_ARADDR = 'bx;
    end
end

always @ (*) begin
    if (((1'b1 == ap_CS_fsm_state13) | (1'b1 == ap_CS_fsm_state12))) begin
        m_axi_gmem_0_ARBURST = grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARBURST;
    end else begin
        m_axi_gmem_0_ARBURST = 2'd0;
    end
end

always @ (*) begin
    if (((1'b1 == ap_CS_fsm_state13) | (1'b1 == ap_CS_fsm_state12))) begin
        m_axi_gmem_0_ARCACHE = grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARCACHE;
    end else begin
        m_axi_gmem_0_ARCACHE = 4'd0;
    end
end

always @ (*) begin
    if (((1'b1 == ap_CS_fsm_state13) | (1'b1 == ap_CS_fsm_state12))) begin
        m_axi_gmem_0_ARID = grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARID;
    end else begin
        m_axi_gmem_0_ARID = 1'd0;
    end
end

always @ (*) begin
    if ((~((m_axi_gmem_0_ARREADY == 1'b0) | (ap_start == 1'b0)) & (1'b1 == ap_CS_fsm_state1))) begin
        m_axi_gmem_0_ARLEN = 64'd768;
    end else if (((1'b1 == ap_CS_fsm_state13) | (1'b1 == ap_CS_fsm_state12))) begin
        m_axi_gmem_0_ARLEN = grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARLEN;
    end else begin
        m_axi_gmem_0_ARLEN = 'bx;
    end
end

always @ (*) begin
    if (((1'b1 == ap_CS_fsm_state13) | (1'b1 == ap_CS_fsm_state12))) begin
        m_axi_gmem_0_ARLOCK = grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARLOCK;
    end else begin
        m_axi_gmem_0_ARLOCK = 2'd0;
    end
end

always @ (*) begin
    if (((1'b1 == ap_CS_fsm_state13) | (1'b1 == ap_CS_fsm_state12))) begin
        m_axi_gmem_0_ARPROT = grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARPROT;
    end else begin
        m_axi_gmem_0_ARPROT = 3'd0;
    end
end

always @ (*) begin
    if (((1'b1 == ap_CS_fsm_state13) | (1'b1 == ap_CS_fsm_state12))) begin
        m_axi_gmem_0_ARQOS = grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARQOS;
    end else begin
        m_axi_gmem_0_ARQOS = 4'd0;
    end
end

always @ (*) begin
    if (((1'b1 == ap_CS_fsm_state13) | (1'b1 == ap_CS_fsm_state12))) begin
        m_axi_gmem_0_ARREGION = grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARREGION;
    end else begin
        m_axi_gmem_0_ARREGION = 4'd0;
    end
end

always @ (*) begin
    if (((1'b1 == ap_CS_fsm_state13) | (1'b1 == ap_CS_fsm_state12))) begin
        m_axi_gmem_0_ARSIZE = grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARSIZE;
    end else begin
        m_axi_gmem_0_ARSIZE = 3'd0;
    end
end

always @ (*) begin
    if (((1'b1 == ap_CS_fsm_state13) | (1'b1 == ap_CS_fsm_state12))) begin
        m_axi_gmem_0_ARUSER = grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARUSER;
    end else begin
        m_axi_gmem_0_ARUSER = 1'd0;
    end
end

always @ (*) begin
    if ((~((m_axi_gmem_0_ARREADY == 1'b0) | (ap_start == 1'b0)) & (1'b1 == ap_CS_fsm_state1))) begin
        m_axi_gmem_0_ARVALID = 1'b1;
    end else if (((1'b1 == ap_CS_fsm_state13) | (1'b1 == ap_CS_fsm_state12))) begin
        m_axi_gmem_0_ARVALID = grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_ARVALID;
    end else begin
        m_axi_gmem_0_ARVALID = 1'b0;
    end
end

always @ (*) begin
    if (((1'b1 == ap_CS_fsm_state13) | (1'b1 == ap_CS_fsm_state12))) begin
        m_axi_gmem_0_RREADY = grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_m_axi_gmem_0_RREADY;
    end else begin
        m_axi_gmem_0_RREADY = 1'b0;
    end
end

always @ (*) begin
    case (ap_CS_fsm)
        ap_ST_fsm_state1 : begin
            if ((~((m_axi_gmem_0_ARREADY == 1'b0) | (ap_start == 1'b0)) & (1'b1 == ap_CS_fsm_state1))) begin
                ap_NS_fsm = ap_ST_fsm_state2;
            end else begin
                ap_NS_fsm = ap_ST_fsm_state1;
            end
        end
        ap_ST_fsm_state2 : begin
            ap_NS_fsm = ap_ST_fsm_state3;
        end
        ap_ST_fsm_state3 : begin
            ap_NS_fsm = ap_ST_fsm_state4;
        end
        ap_ST_fsm_state4 : begin
            ap_NS_fsm = ap_ST_fsm_state5;
        end
        ap_ST_fsm_state5 : begin
            ap_NS_fsm = ap_ST_fsm_state6;
        end
        ap_ST_fsm_state6 : begin
            ap_NS_fsm = ap_ST_fsm_state7;
        end
        ap_ST_fsm_state7 : begin
            ap_NS_fsm = ap_ST_fsm_state8;
        end
        ap_ST_fsm_state8 : begin
            ap_NS_fsm = ap_ST_fsm_state9;
        end
        ap_ST_fsm_state9 : begin
            ap_NS_fsm = ap_ST_fsm_state10;
        end
        ap_ST_fsm_state10 : begin
            ap_NS_fsm = ap_ST_fsm_state11;
        end
        ap_ST_fsm_state11 : begin
            ap_NS_fsm = ap_ST_fsm_state12;
        end
        ap_ST_fsm_state12 : begin
            ap_NS_fsm = ap_ST_fsm_state13;
        end
        ap_ST_fsm_state13 : begin
            if (((1'b1 == ap_CS_fsm_state13) & (grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_ap_done == 1'b1))) begin
                ap_NS_fsm = ap_ST_fsm_state1;
            end else begin
                ap_NS_fsm = ap_ST_fsm_state13;
            end
        end
        default : begin
            ap_NS_fsm = 'bx;
        end
    endcase
end

assign ap_CS_fsm_state1 = ap_CS_fsm[32'd0];

assign ap_CS_fsm_state12 = ap_CS_fsm[32'd11];

assign ap_CS_fsm_state13 = ap_CS_fsm[32'd12];

assign grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_ap_start = grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_ap_start_reg;

assign m_axi_gmem_0_AWADDR = 64'd0;

assign m_axi_gmem_0_AWBURST = 2'd0;

assign m_axi_gmem_0_AWCACHE = 4'd0;

assign m_axi_gmem_0_AWID = 1'd0;

assign m_axi_gmem_0_AWLEN = 32'd0;

assign m_axi_gmem_0_AWLOCK = 2'd0;

assign m_axi_gmem_0_AWPROT = 3'd0;

assign m_axi_gmem_0_AWQOS = 4'd0;

assign m_axi_gmem_0_AWREGION = 4'd0;

assign m_axi_gmem_0_AWSIZE = 3'd0;

assign m_axi_gmem_0_AWUSER = 1'd0;

assign m_axi_gmem_0_AWVALID = 1'b0;

assign m_axi_gmem_0_BREADY = 1'b0;

assign m_axi_gmem_0_WDATA = 32'd0;

assign m_axi_gmem_0_WID = 1'd0;

assign m_axi_gmem_0_WLAST = 1'b0;

assign m_axi_gmem_0_WSTRB = 4'd0;

assign m_axi_gmem_0_WUSER = 1'd0;

assign m_axi_gmem_0_WVALID = 1'b0;

assign sext_ln12_fu_70_p1 = trunc_ln_fu_60_p4;

assign trunc_ln_fu_60_p4 = {{tsor[63:2]}};

assign x_strm_din = grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_x_strm_din;

assign x_strm_write = grp_push_tensor1d_Pipeline_VITIS_LOOP_12_1_fu_51_x_strm_write;

endmodule //FFN_push_tensor1d
